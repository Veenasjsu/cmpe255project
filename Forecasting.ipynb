{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da9bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from google.cloud import bigquery\n",
    "import dash\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec69a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project_id, dataset_id, table_id):\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "    df = client.query(f\"SELECT * FROM `{table_ref}`\").to_dataframe()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #print(df.head())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c6eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, seasonal=True):\n",
    "    df_f = df[df['Seasonally Adjusted'] == seasonal]\n",
    "    ts = df_f.pivot_table(index='Date', columns='Industry Title', values='Current Employment').sort_index()\n",
    "    ts = ts.asfreq('MS')\n",
    "    ts = ts.interpolate(method='time').ffill().bfill()\n",
    "    scaler = MinMaxScaler()\n",
    "    ts = pd.DataFrame(scaler.fit_transform(ts), index=ts.index, columns=ts.columns)\n",
    "\n",
    "    return ts, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b875159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=1):\n",
    "        super(LSTMForecast, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        # take the output of the last time step\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def forecast_lstm_pytorch(series, periods=12, look_back=12, epochs=50, lr=0.001):\n",
    "    # Scale the series to [0,1]\n",
    "    values = series.values.astype('float32').reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(values).flatten()\n",
    "\n",
    "    # Prepare sequences\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled) - look_back):\n",
    "        X.append(scaled[i:i + look_back])\n",
    "        y.append(scaled[i + look_back])\n",
    "    X = torch.tensor(np.array(X)).unsqueeze(-1)  # shape [samples, look_back, 1]\n",
    "    y = torch.tensor(np.array(y)).unsqueeze(-1)  # shape [samples, 1]\n",
    "\n",
    "    # Initialize model, loss, optimizer\n",
    "    model = LSTMForecast(input_size=1, hidden_size=50)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Forecast future points\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    last_seq = torch.tensor(scaled[-look_back:]).unsqueeze(0).unsqueeze(-1)  # shape [1, look_back, 1]\n",
    "    with torch.no_grad():\n",
    "        for _ in range(periods):\n",
    "            pred = model(last_seq)\n",
    "            preds.append(pred.item())\n",
    "            next_seq = last_seq.squeeze().numpy().flatten().tolist()[1:] + [pred.item()]\n",
    "            last_seq = torch.tensor(next_seq).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "    # Invert scaling\n",
    "    preds = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Build forecast index\n",
    "    idx = pd.date_range(series.index[-1] + pd.offsets.MonthEnd(), periods=periods, freq='ME')\n",
    "    return idx, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a654051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_arima(series, periods=12, auto=False):\n",
    "    order, seasonal_order = (1,1,1), (1,1,1,12)\n",
    "    if auto:\n",
    "        best_aic, best_cfg = np.inf, None\n",
    "        for p in range(2):\n",
    "            for d in range(2):\n",
    "                for q in range(2):\n",
    "                    try:\n",
    "                        res = ARIMA(series, order=(p,d,q), seasonal_order=seasonal_order).fit()\n",
    "                        if res.aic < best_aic:\n",
    "                            best_aic, best_cfg = res.aic, (p,d,q)\n",
    "                    except:\n",
    "                        continue\n",
    "        if best_cfg:\n",
    "            order = best_cfg\n",
    "    model = ARIMA(series, order=order, seasonal_order=seasonal_order).fit()\n",
    "    fc = model.forecast(steps=periods)\n",
    "    idx = pd.date_range(series.index[-1] + pd.offsets.MonthEnd(), periods=periods, freq='ME')\n",
    "    return idx, fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8940b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_prophet(series, periods=12):\n",
    "    dfp = series.reset_index().rename(columns={'Date':'ds', series.name:'y'})\n",
    "    m = Prophet()\n",
    "    m.fit(dfp)\n",
    "    future = m.make_future_dataframe(periods=periods, freq='ME')\n",
    "    f = m.predict(future)\n",
    "    return f['ds'][-periods:].values, f['yhat'][-periods:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fb6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1957: UserWarning:\n",
      "\n",
      "BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args......................... Namespace(report=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dash\\dash.py:587: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "16:02:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:02:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2c7a4724230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "16:03:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:03:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:03:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:03:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "16:12:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:13:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:38:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:38:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning:\n",
      "\n",
      "Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning:\n",
      "\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:39:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:39:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:48:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "c:\\Users\\veena\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "16:48:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:48:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "def generate_report(ts, scaler, industries, report_path='report.md'):\n",
    "    lines = [f\"# Employment Trend Analysis Report\", f\"Generated on {pd.Timestamp.now()}\", \"\"]\n",
    "    for ind in industries:\n",
    "        series = ts[ind]\n",
    "        idx_a, fa = forecast_arima(series, auto=True)\n",
    "        mae = mean_absolute_error(series[-len(fa):], fa)\n",
    "        rmse = np.sqrt(mean_squared_error(series[-len(fa):], fa))\n",
    "        \n",
    "        lines.append(f\"## {ind}\")\n",
    "        lines.append(f\"- ARIMA MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(series.index, series, label='Historical')\n",
    "        plt.plot(idx_a, fa, label='Forecast')\n",
    "        \n",
    "        plt.legend()\n",
    "        img = f\"{ind.replace(' ','_')}.png\"\n",
    "        plt.savefig(img)\n",
    "        plt.close()\n",
    "        lines.append(f\"![{ind}]({img})\")\n",
    "        lines.append(\"\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write('\\n'.join(lines))\n",
    "    print(f\"Report written to {report_path}\")\n",
    "\n",
    "\n",
    "def create_dashboard(ts, industries):\n",
    "\n",
    "    def make_figures(ind):\n",
    "        series = ts[ind].dropna()\n",
    "\n",
    "        # ARIMA forecast\n",
    "        idx_a, fa = forecast_arima(series, auto=True)\n",
    "        # Prophet forecast\n",
    "        idx_p, fp = forecast_prophet(series)\n",
    "        # PyTorch LSTM forecast\n",
    "        idx_l, fl = forecast_lstm_pytorch(series)\n",
    "\n",
    "        # Build a Plotly Figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Historical trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=series.index, y=series.values,\n",
    "            mode='lines', name='Historical'\n",
    "        ))\n",
    "\n",
    "        # ARIMA trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=idx_a, y=fa,\n",
    "            mode='lines', name='ARIMA'\n",
    "        ))\n",
    "\n",
    "        # Prophet trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=idx_p, y=fp,\n",
    "            mode='lines', name='Prophet'\n",
    "        ))\n",
    "\n",
    "        # LSTM trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=idx_l, y=fl,\n",
    "            mode='lines', name='LSTM'\n",
    "        ))\n",
    "\n",
    "        # **Hereâ€™s the title addition:**\n",
    "        fig.update_layout(\n",
    "            title=f\"Forecast Comparison for {ind}\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Current Employment\",\n",
    "            height=400,\n",
    "            template=\"simple_white\"\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    app = JupyterDash(__name__)\n",
    "    default_ind = industries[0]\n",
    "    init_fig = make_figures(default_ind)\n",
    "\n",
    "    app.layout = html.Div([\n",
    "        html.H1(\"Employment Trend Analysis\"),\n",
    "        dcc.Dropdown(\n",
    "            id='industry-dropdown',\n",
    "            options=[{'label':i,'value':i} for i in industries],\n",
    "            value=default_ind,\n",
    "            clearable=False\n",
    "        ),\n",
    "        dcc.Graph(id='forecast-graph', figure=init_fig)\n",
    "    ])\n",
    "\n",
    "    @app.callback(\n",
    "        Output('forecast-graph', 'figure'),\n",
    "        Input('industry-dropdown', 'value')\n",
    "    )\n",
    "    def update_forecast(ind):\n",
    "        return make_figures(ind)\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "def compute_all_metrics(ts, periods=12):\n",
    "    records = []\n",
    "    for ind in ts.columns:\n",
    "        series = ts[ind]\n",
    "        # 1. Get forecasts\n",
    "        idx_ar, fc_ar = forecast_arima(series, periods=periods)\n",
    "        _,        fc_pr = forecast_prophet(series.rename(ind), periods=periods)\n",
    "        _,        fc_ls = forecast_lstm_pytorch(series, periods=periods)\n",
    "\n",
    "        # Align true values; here we compare on the last <periods> points\n",
    "        true = series[-periods:]\n",
    "\n",
    "        # 2. MAPE helper\n",
    "        def mape(y_true, y_pred):\n",
    "            return (np.abs((y_true - y_pred) / y_true).dropna().mean()) * 100\n",
    "\n",
    "        # 3. Record metrics\n",
    "        for model, pred in [('ARIMA', fc_ar), ('Prophet', fc_pr), ('LSTM', fc_ls)]:\n",
    "            mae   = mean_absolute_error(true, pred)\n",
    "            mse   = mean_squared_error( true, pred )       \n",
    "            rmse  = np.sqrt(mse)                           \n",
    "            mapev = mape(true, pred)\n",
    "            records.append({\n",
    "                'industry':  ind,\n",
    "                'model':     model,\n",
    "                'MAE':       mae,\n",
    "                'RMSE':      rmse,\n",
    "                'MAPE(%)':   mapev\n",
    "            })\n",
    "\n",
    "    df_metrics = pd.DataFrame(records)\n",
    "    df_metrics.to_csv('metrics_summary.csv', index=False)\n",
    "\n",
    "    # Display a pivoted table for slides\n",
    "    display(df_metrics.pivot_table(\n",
    "        index='industry',\n",
    "        columns='model',\n",
    "        values=['MAE','RMSE','MAPE(%)']\n",
    "    ))\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--report', action='store_true')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    pid = os.getenv('PROJECT_ID','dm-project-458907')\n",
    "    did = os.getenv('DATASET_ID','CurrentEmploymentStatistics')\n",
    "    tid = os.getenv('TABLE_ID','ces')\n",
    "    df = load_data(pid, did, tid)\n",
    "    ts, scaler = preprocess(df)\n",
    "    inds = ts.columns.tolist()\n",
    "    #metrics_df = compute_all_metrics(ts)\n",
    "    print('args.........................',args)\n",
    "    if args.report:\n",
    "      generate_report(ts, scaler, inds)\n",
    "    else:\n",
    "      app = create_dashboard(ts, inds)\n",
    "      app.run(mode='inline', port=8052)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
